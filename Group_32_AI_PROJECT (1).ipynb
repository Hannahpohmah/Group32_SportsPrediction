{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_F6q74i6aIm"
      },
      "source": [
        "#Import libraries and mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSESlEHHlUYg",
        "outputId": "457d82fc-6484-43e3-e14c-5ea26804aaae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np283QOk7ISU"
      },
      "source": [
        "#Data pre-processing and feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzJg16_hTo4M"
      },
      "outputs": [],
      "source": [
        "players_21 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/colab files/players_21.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq4MeBwGfxmn",
        "outputId": "23f6e0c8-ddc0-4882-c032-552ba3fe43d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-c0af8ff2dfb1>:1: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  players_22 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/colab files/players_22.csv')\n"
          ]
        }
      ],
      "source": [
        "players_22 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/colab files/players_22.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1L1W20tT72q",
        "outputId": "14dfa22e-9931-40c9-cf4b-3798f409480e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18944 entries, 0 to 18943\n",
            "Columns: 110 entries, sofifa_id to nation_flag_url\n",
            "dtypes: float64(16), int64(44), object(50)\n",
            "memory usage: 15.9+ MB\n"
          ]
        }
      ],
      "source": [
        "players_21.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zxHp_yoZAa2",
        "outputId": "c75105fb-c40b-42fa-dde2-a409d6a763c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sofifa_id', 'player_url', 'short_name', 'long_name', 'player_positions', 'overall', 'potential', 'value_eur', 'wage_eur', 'age', 'dob', 'height_cm', 'weight_kg', 'club_team_id', 'club_name', 'league_name', 'league_level', 'club_position', 'club_jersey_number', 'club_loaned_from', 'club_joined', 'club_contract_valid_until', 'nationality_id', 'nationality_name', 'nation_team_id', 'nation_position', 'nation_jersey_number', 'preferred_foot', 'weak_foot', 'skill_moves', 'international_reputation', 'work_rate', 'body_type', 'real_face', 'release_clause_eur', 'player_tags', 'player_traits', 'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', 'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', 'defending_marking_awareness', 'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk', 'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url']\n"
          ]
        }
      ],
      "source": [
        "columns_list = players_21.columns.tolist()\n",
        "print(columns_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW9ybDR2V8v1"
      },
      "outputs": [],
      "source": [
        "#Dropping columns with data sets that have 50% missing values\n",
        "cols_to_drop = []\n",
        "for i in players_21.columns:\n",
        "    missing = np.abs((players_21[i].count() - players_21[i].shape[0])/players_21[i].shape[0] * 100)\n",
        "    if missing > 50:\n",
        "        print('{} - {}%'.format(i, round(missing)))\n",
        "        cols_to_drop.append(i)\n",
        "\n",
        "players_21.drop(columns=cols_to_drop,inplace=True)\n",
        "print(players_21.shape)\n",
        "\n",
        "columns_to_drop = ['sofifa_id', 'player_url', 'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_flag_url']\n",
        "players_21.drop(columns=columns_to_drop,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDsoIftgbsFv"
      },
      "outputs": [],
      "source": [
        "# Split dataset into categorical and numeric\n",
        "selected_columns= ['club_name','club_position','league_name','preferred_foot']\n",
        "categorical_data =players_21[selected_columns]\n",
        "numeric_data = players_21.select_dtypes(exclude=['object'])\n",
        "\n",
        "\n",
        "#imputing numeric\n",
        "imp=SimpleImputer()\n",
        "imputed_data=imp.fit_transform(numeric_data)\n",
        "df_numeric =pd.DataFrame(imputed_data, columns=numeric_data.columns)\n",
        "\n",
        "#imputing non_numeric\n",
        "df = pd.DataFrame(categorical_data )\n",
        "columns=categorical_data.columns\n",
        "modes = df[columns].mode().iloc[0]\n",
        "df[columns] = df[columns].fillna(modes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnK0BKWoq_ya"
      },
      "outputs": [],
      "source": [
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "columns_to_encode = df.columns  # Replace with your actual column names\n",
        "\n",
        "encoded_df = pd.DataFrame()\n",
        "df['preferred_foot'] = label_encoder.fit_transform(df['preferred_foot'])\n",
        "df['club_position'] =  label_encoder.fit_transform(df['club_position'])\n",
        "df['club_name'] =  label_encoder.fit_transform(df['club_name'])\n",
        "df['league_name'] =  label_encoder.fit_transform(df['league_name'])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skeBquHmKw8M"
      },
      "outputs": [],
      "source": [
        "New_players_21 = pd.concat([df_numeric,df], axis=1)\n",
        "New_players_21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjEo5XDo4esj"
      },
      "outputs": [],
      "source": [
        "# Replace these with your data and model\n",
        "overall= New_players_21['overall']\n",
        "features= New_players_21.drop(columns='overall')\n",
        "X = pd.DataFrame(features)  # Your feature data\n",
        "y = pd.Series(overall)    # Your target variable\n",
        "rf_model = RandomForestRegressor()  # Your trained model\n",
        "\n",
        "# Train the model on your data\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to visualize feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "\n",
        "# Sort features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "# Print or visualize feature importance\n",
        "feature_importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztILFkVzUmHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bf2b60-8dd4-4c16-d269-33a5782779e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['value_eur',\n",
              " 'release_clause_eur',\n",
              " 'age',\n",
              " 'potential',\n",
              " 'movement_reactions',\n",
              " 'wage_eur',\n",
              " 'defending',\n",
              " 'club_name',\n",
              " 'mentality_interceptions',\n",
              " 'league_name',\n",
              " 'attacking_crossing',\n",
              " 'goalkeeping_diving',\n",
              " 'mentality_composure',\n",
              " 'goalkeeping_reflexes',\n",
              " 'defending_marking_awareness',\n",
              " 'goalkeeping_positioning',\n",
              " 'defending_standing_tackle',\n",
              " 'mentality_penalties']"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "features= New_players_21.drop(columns='overall')# Replace with your actual feature names\n",
        "X = pd.DataFrame(features)\n",
        "your_feature_names= X.columns\n",
        "\n",
        "# Sort features by importance\n",
        "feature_indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Select the top 10 features\n",
        "top_10_feature_indices = feature_indices[:18]\n",
        "\n",
        "# Get the names of the top 10 features\n",
        "top_15_feature_names = [your_feature_names[i] for i in top_10_feature_indices]\n",
        "top_15_feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAFkTkdwng3U"
      },
      "source": [
        "#Checking for maximum correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TkI_c9PN8k2"
      },
      "outputs": [],
      "source": [
        "cols= ['value_eur',\n",
        " 'release_clause_eur',\n",
        " 'age','overall',\n",
        " 'potential',\n",
        " 'movement_reactions',\n",
        " 'wage_eur',\n",
        " 'defending',\n",
        " 'club_name',\n",
        " 'mentality_interceptions',\n",
        " 'league_name',\n",
        " 'attacking_crossing',\n",
        " 'goalkeeping_diving',\n",
        " 'mentality_composure',\n",
        " 'goalkeeping_reflexes',\n",
        " 'defending_marking_awareness',\n",
        " 'goalkeeping_positioning',\n",
        " 'defending_standing_tackle',\n",
        " 'mentality_penalties']\n",
        "Cleaned_player_21= New_players_21[cols ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElHDpeGjqb_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b00d902-d18a-4f65-a208-9fd1cad5e921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 1: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 2: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 3: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 4: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 5: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 6: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 7: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 8: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 9: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 10: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 11: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 12: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 13: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 14: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n",
            "Subset 15: [3, 5, 13, 4, 1, 6, 0, 2, 11, 7, 18, 15, 9, 17, 16, 10, 14, 12]\n"
          ]
        }
      ],
      "source": [
        "def find_max_corr_features(data, dependent_variable, num_subsets):\n",
        "    max_corr_subsets = []\n",
        "\n",
        "    # Correlation matrix\n",
        "    corr_matrix = data.corr().abs()\n",
        "\n",
        "    # Column indices of features sorted by correlation with dependent variable\n",
        "    sorted_features = np.argsort(corr_matrix[dependent_variable])[::-1]\n",
        "\n",
        "    for _ in range(num_subsets):\n",
        "        subset = []\n",
        "        for i in sorted_features:\n",
        "            if i not in subset:\n",
        "                subset.append(i)\n",
        "                if len(subset) == data.shape[1] - 1:\n",
        "                    break\n",
        "        max_corr_subsets.append(subset)\n",
        "\n",
        "    return max_corr_subsets\n",
        "\n",
        "\n",
        "dependent_variable = 'overall'\n",
        "num_subsets = 15\n",
        "\n",
        "max_corr_subsets = find_max_corr_features(Cleaned_player_21, dependent_variable, num_subsets)\n",
        "\n",
        "for i, subset in enumerate(max_corr_subsets):\n",
        "    print(f\"Subset {i + 1}: {subset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EXpr6okmiFw"
      },
      "outputs": [],
      "source": [
        "X = Cleaned_player_21.drop(columns='overall')\n",
        "y = players_21['overall']\n",
        "\n",
        "#Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nobh2h2Pm8-C"
      },
      "outputs": [],
      "source": [
        "#Scaling\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "from joblib import dump\n",
        "dump(scaler, 'scaler.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWm_uSZfdsS8"
      },
      "source": [
        "Training suitable machine learning models with cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtUTEY6Gsgr0"
      },
      "source": [
        "#The Random forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLlCpIe2mpDc",
        "outputId": "2687790f-33d6-4033-fab2-0d72facc88dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model CV Mean Accuracy Score: 0.9949660328597286\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Perform cross-validation and print the mean accuracy score\n",
        "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
        "mean_cv_scores_rf=np.mean(cv_scores)\n",
        "print(f\"Random Forest Model CV Mean Accuracy Score: {mean_cv_scores_rf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1c07vEJw3Q-",
        "outputId": "84f49cb1-bc32-455d-fc75-b3bb4479a89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor(random_state=42)\n",
            "MAE: 0.28228373474100976\n",
            "RMSE: 0.49902644248599787\n"
          ]
        }
      ],
      "source": [
        "#Make the prediction\n",
        "y_pred = cross_val_predict(rf_model, X_train, y_train, cv=5)\n",
        "print(rf_model)\n",
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine tuning the random forest model\n",
        "# Define the parameter grid\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [None, 3, 5],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a RandomForestRegressor model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search_rf = GridSearchCV(\n",
        "    rf_model, param_grid_rf, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search_rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "5fS-jsswTozh",
        "outputId": "9846b206-62b1-4cfc-f9c5-8375cd795d1a"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={'max_depth': [None, 3, 5],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5],\n",
              "                         'n_estimators': [50, 100, 150, 200]},\n",
              "             scoring='neg_mean_absolute_error')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 3, 5],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 3, 5],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search_rf.best_params_\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "mae = mean_absolute_error(y_test, y_pred )\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred ))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMAUJCNaWaTL",
        "outputId": "e31a9623-c51b-441f-dbcf-80ead7526fe0"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "MAE: 0.2524795460543679\n",
            "RMSE: 0.458368270459983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8zqbSPksjKp"
      },
      "source": [
        "#The Gradient Boosting Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZRpH_s4mt2u",
        "outputId": "49ab891b-1874-41e4-cf45-1bafce6f5519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model CV Mean Accuracy Score: 0.987042481600052\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Perform cross-validation and print the mean accuracy score\n",
        "cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5)\n",
        "mean_cv_scores_gr = np.mean(cv_scores)\n",
        "print(f\"Gradient Boosting Model CV Mean Accuracy Score: {mean_cv_scores_gr}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvWdxRBzxlrz",
        "outputId": "f2f2d81f-690e-4721-80da-5bcc8406d7af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[49.79391239 55.36701472 67.55387371 ... 70.24190653 77.3986622\n",
            " 59.18018458]\n",
            "MAE: 0.5866570858825924\n",
            "RMSE: 0.8004806693204713\n"
          ]
        }
      ],
      "source": [
        "#Make the prediction\n",
        "y_pred = cross_val_predict(gb_model, X_train, y_train, cv=5)\n",
        "print(y_pred)\n",
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning the gradient boost\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [50,150],\n",
        "    'learning_rate': [0.01, 0.05],\n",
        "    'max_depth': [4, 5],\n",
        "    'min_samples_split': [2],\n",
        "    'min_samples_leaf': [1],\n",
        "    'subsample': [0.8, 0.9]\n",
        "}\n",
        "\n",
        "# Create a GradientBoostingRegressor model\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search_gb = GridSearchCV(\n",
        "    gb_model, param_grid_gb, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model to the training data"
      ],
      "metadata": {
        "id": "hnG8XclqVYmM"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_gb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "6nsI1p4ktV-s",
        "outputId": "40be21ff-fb8b-4a2d-e8b3-464394cfb701"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.01, 0.05], 'max_depth': [4, 5],\n",
              "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
              "                         'n_estimators': [50, 150], 'subsample': [0.8, 0.9]},\n",
              "             scoring='neg_mean_absolute_error')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05], &#x27;max_depth&#x27;: [4, 5],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1], &#x27;min_samples_split&#x27;: [2],\n",
              "                         &#x27;n_estimators&#x27;: [50, 150], &#x27;subsample&#x27;: [0.8, 0.9]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05], &#x27;max_depth&#x27;: [4, 5],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1], &#x27;min_samples_split&#x27;: [2],\n",
              "                         &#x27;n_estimators&#x27;: [50, 150], &#x27;subsample&#x27;: [0.8, 0.9]},\n",
              "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search_gb.best_params_\n",
        "best_gb_model = grid_search_gb.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# You can use metrics like mean absolute error, mean squared error, etc. to evaluate the model.\n",
        "mae = mean_absolute_error(y_test, y_pred )\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred ))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX9f2JaIcy0p",
        "outputId": "71eca8b4-de9a-484d-9911-f322b7775df7"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150, 'subsample': 0.8}\n",
            "MAE: 0.3815831892026116\n",
            "RMSE: 0.5461495666785222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL0HwN1IMHN8"
      },
      "source": [
        "# The XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsnVx0BzkBIW",
        "outputId": "a8ee57c2-efdd-4576-e074-61d5c496c9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average 5-Fold Cross-Validation Score: -0.2646\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators=100)\n",
        "\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "average_score = np.mean(xgb_scores)\n",
        "\n",
        "print(\"Average 5-Fold Cross-Validation Score: {:.4f}\".format(average_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgO3gxL_kDy6",
        "outputId": "434ee8de-d71c-420a-cc87-35356d90a853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[49.847084 54.623714 67.040054 ... 69.9997   77.64766  58.761818]\n",
            "MAE: 0.3535913737368481\n",
            "RMSE: 0.5144169828917263\n"
          ]
        }
      ],
      "source": [
        "xgb_predictions = cross_val_predict(xgb_model, X_train, y_train, cv=5)\n",
        "print(xgb_predictions)\n",
        "\n",
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "mae = mean_absolute_error(y_train, xgb_predictions)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, xgb_predictions))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fine tuning the xbgboost\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'min_child_weight': [1, 2, 3],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "}\n",
        "\n",
        "# Create an XGBRegressor model\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    xgb_model, param_grid_xgb, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator\n",
        "best_params = grid_search_xgb.best_params_\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred = best_xgb_model.predict(X_test)\n",
        "\n",
        "#Measure the model's performance using the Mean absolute error and the Root mean squared error\n",
        "mae = mean_absolute_error(y_test, y_pred )\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred ))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slNoqMG2V3_c",
        "outputId": "67a3063b-f083-41f5-f078-7bba09b0e4da"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 200, 'subsample': 1.0}\n",
            "MAE: 0.32042474613305477\n",
            "RMSE: 0.4644767454362285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1XR-TmjsMIe"
      },
      "source": [
        "#Custom ensemble model: The stacking regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBc4SSw9ujew"
      },
      "source": [
        "Determine the ensemble's model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JpLBEtrkrZk",
        "outputId": "6e0a954c-a4b4-4b7b-9829-235836a04602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.24585374523574616\n",
            "RMSE: 0.47100813937535624\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Create the base regressor models\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Create the stacking regressor\n",
        "stacking_regressor = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('rf', rf_model),\n",
        "        ('gb', gb_model)\n",
        "    ],\n",
        "    final_estimator=XGBRegressor(random_state=42)  # You can adjust hyperparameters here\n",
        ")\n",
        "\n",
        "# Fit the stacking regressor to the training set\n",
        "stacking_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable for the test set\n",
        "stacking_preds = stacking_regressor.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, stacking_preds)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, stacking_preds))\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "best_model= stacking_regressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVrukiih9tSC"
      },
      "source": [
        "#Test ensemble model on the Players_22 data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GTUf9tG-hZC"
      },
      "source": [
        "Load the trained ensemble model and test it's performance on the Players_22 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "Y893r4kU98lb"
      },
      "outputs": [],
      "source": [
        "# Test the model on players_22\n",
        "cols= ['value_eur',\n",
        " 'release_clause_eur',\n",
        " 'age','overall',\n",
        " 'potential',\n",
        " 'movement_reactions',\n",
        " 'wage_eur',\n",
        " 'defending',\n",
        " 'mentality_interceptions',\n",
        " 'attacking_crossing',\n",
        " 'goalkeeping_diving',\n",
        " 'mentality_composure',\n",
        " 'goalkeeping_reflexes',\n",
        " 'defending_marking_awareness',\n",
        " 'goalkeeping_positioning',\n",
        " 'defending_standing_tackle',\n",
        " 'mentality_penalties','club_name','league_name']\n",
        "players_22_Data= players_22[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "_QKQbc_pinh5"
      },
      "outputs": [],
      "source": [
        "# Split dataset into categorical and numeric\n",
        "selected_columns= ['club_name','league_name']\n",
        "categorical_data =players_22_Data[selected_columns]\n",
        "numeric_data = players_22_Data.select_dtypes(exclude=['object'])\n",
        "\n",
        "\n",
        "#imputing numeric\n",
        "imp=SimpleImputer()\n",
        "imputed_data=imp.fit_transform(numeric_data)\n",
        "df_numeric =pd.DataFrame(imputed_data, columns=numeric_data.columns)\n",
        "\n",
        "#imputing non_numeric\n",
        "df = pd.DataFrame(categorical_data )\n",
        "columns=categorical_data.columns\n",
        "modes = df[columns].mode().iloc[0]\n",
        "df[columns] = df[columns].fillna(modes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "columns_to_encode = df.columns  # Replace with your actual column names\n",
        "\n",
        "encoded_df = pd.DataFrame()\n",
        "\n",
        "df['club_name'] =  label_encoder.fit_transform(df['club_name'])\n",
        "df['league_name'] =  label_encoder.fit_transform(df['league_name'])\n",
        "\n",
        "New_players_22 = pd.concat([df_numeric,df], axis=1)\n",
        "New_players_22.columns"
      ],
      "metadata": {
        "id": "59EbBDC4knfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2678db35-3d7a-486f-9708-cdf3f4c38dc9"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['value_eur', 'release_clause_eur', 'age', 'overall', 'potential',\n",
              "       'movement_reactions', 'wage_eur', 'defending',\n",
              "       'mentality_interceptions', 'attacking_crossing', 'goalkeeping_diving',\n",
              "       'mentality_composure', 'goalkeeping_reflexes',\n",
              "       'defending_marking_awareness', 'goalkeeping_positioning',\n",
              "       'defending_standing_tackle', 'mentality_penalties', 'club_name',\n",
              "       'league_name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = New_players_22.drop(columns='overall')\n",
        "X.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFcnLawVzMyn",
        "outputId": "a5d0218e-bc5a-4b76-d00f-eebfc131689b"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['value_eur', 'release_clause_eur', 'age', 'potential',\n",
              "       'movement_reactions', 'wage_eur', 'defending',\n",
              "       'mentality_interceptions', 'attacking_crossing', 'goalkeeping_diving',\n",
              "       'mentality_composure', 'goalkeeping_reflexes',\n",
              "       'defending_marking_awareness', 'goalkeeping_positioning',\n",
              "       'defending_standing_tackle', 'mentality_penalties', 'club_name',\n",
              "       'league_name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "Xboo_0b3i_xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d553c93-7e18-4bba-ccea-75ee9dc480c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.6691602158301742\n"
          ]
        }
      ],
      "source": [
        "X = New_players_22.drop(columns='overall')\n",
        "y = New_players_22['overall']\n",
        "X = X[['value_eur', 'release_clause_eur', 'age', 'potential', 'movement_reactions', 'wage_eur', 'defending', 'club_name','mentality_interceptions','league_name', 'attacking_crossing', 'goalkeeping_diving', 'mentality_composure', 'goalkeeping_reflexes', 'defending_marking_awareness', 'goalkeeping_positioning', 'defending_standing_tackle', 'mentality_penalties']]\n",
        "\n",
        "#Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "gSVa_8AVZe3p"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Use pickle to save the trained model\n",
        "with open('best_model.plk', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8_F6q74i6aIm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}